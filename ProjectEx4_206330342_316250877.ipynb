{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "554aceee",
   "metadata": {},
   "source": [
    "## Part 1 - Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "33361040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm, t\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "92ac96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('framingham_heart_disease.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc1563b",
   "metadata": {},
   "source": [
    "### Section 1\n",
    "Reminder from previous part:<br>\n",
    "We would like to explore the relations between: Number of cigaretes per day (discrete), total cholesterol (continous), diaBP (diastolic BP) and sysBP (systolic BP - continous). <br>\n",
    "Hence, our research question would be:\n",
    "**What are the effects of number of cigaretes per day, total cholesterol and diaBP over sysBP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae3cec",
   "metadata": {},
   "source": [
    "Preparing the subset that we will work with, as done in part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0e97400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['cigsPerDay', 'totChol', 'diaBP', 'sysBP'], inplace=True)\n",
    "df_train, df_test, y_train, y_test = train_test_split(df[['cigsPerDay', 'totChol', 'diaBP']], df[['sysBP']], test_size=0.9519115171916326, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d00dfae",
   "metadata": {},
   "source": [
    "#### section a - calculating confidence intervals based on the variance matrix and normal approximation \n",
    "Calculating the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ece3826f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const        -6.795017\n",
       "cigsPerDay   -0.002428\n",
       "totChol       0.055739\n",
       "diaBP         1.520925\n",
       "dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.add_constant(df_train)\n",
    "model = sm.OLS(y_train,X)\n",
    "model_res = model.fit()\n",
    "model_res.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bdc3a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the variance is unknown we will compute it using the unbiased estimator as shown in tutorial 5\n",
    "dof = len(df_train)-2\n",
    "sigma_squared = np.dot(model_res.resid.to_numpy().T,model_res.resid.to_numpy())/(len(df_train)-4)\n",
    "ci_t_percentile = norm().ppf(0.95)\n",
    "C = np.linalg.inv(np.matmul(X.T,X))  # C = (X.T * X)^-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "024cbcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval for beta_0 is: [-20.120873608415245,6.530840172599772]\n",
      "Confidence interval for beta_1 is: [-0.12499805793941654,0.12014199808401821]\n",
      "Confidence interval for beta_2 is: [0.024470264676292097,0.08700841545378751]\n",
      "Confidence interval for beta_3 is: [1.3755587622140237,1.6662906536246527]\n"
     ]
    }
   ],
   "source": [
    "for i, beta in enumerate(model_res.params):\n",
    "    print(f\"Confidence interval for beta_{i} is: [{beta - ci_t_percentile*np.sqrt(sigma_squared*C[i,i])},{beta + ci_t_percentile*np.sqrt(sigma_squared*C[i,i])}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc95a14",
   "metadata": {},
   "source": [
    "#### section b - confidence intervals based on bootsrtap standart error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7bad8160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_bootstrap_normal_se(B, df, features_cols, label_cols):\n",
    "    df_len = len(df)\n",
    "    num_param = len(df.columns)\n",
    "    param_sum = np.zeros((num_param))\n",
    "    param_sum2 = np.zeros((num_param))\n",
    "    for i in range(B):\n",
    "        boot_df = df.sample(replace=True, n=200)\n",
    "        y = boot_df[label_cols]\n",
    "        X = boot_df[features_cols]\n",
    "        X['const'] = np.ones((df_len))\n",
    "        X = X[['const', *features_cols]]\n",
    "        model = sm.OLS(y,X)\n",
    "        model_res = model.fit()\n",
    "        param_sum = param_sum + model_res.params\n",
    "        param_sum2 = param_sum2 + (model_res.params) ** 2\n",
    "    return np.sqrt((1/B)*(param_sum2) - ((1/B)*(param_sum))**2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7f8568ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_se = cal_bootstrap_normal_se(400, pd.concat([df_train, y_train], axis=1),\n",
    "                        features_cols=['cigsPerDay', 'totChol', 'diaBP'], label_cols=['sysBP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0ec85885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval based on bootstrap s.e for beta_0 is: [-22.421727467353975,8.831694031538504]\n",
      "Confidence interval based on bootstrap s.e for beta_1 is: [-0.1280283894501285,0.12317232959473018]\n",
      "Confidence interval based on bootstrap s.e for beta_2 is: [0.020901276721573894,0.09057740340850572]\n",
      "Confidence interval based on bootstrap s.e for beta_3 is: [1.356657609459274,1.6851918063794025]\n"
     ]
    }
   ],
   "source": [
    "for i, beta in enumerate(model_res.params):\n",
    "    print(f\"Confidence interval based on bootstrap s.e for beta_{i} is: [{beta - ci_t_percentile*bootstrap_se[i]},{beta + ci_t_percentile*bootstrap_se[i]}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd575e",
   "metadata": {},
   "source": [
    "#### section c - pivotals confidence intervals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4bc52f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_boot_pivot_quantile(B, df, features_cols, labels_cols, alpha):\n",
    "    num_sample = len(df)\n",
    "    q = 1 - alpha/2\n",
    "    g_dict = defaultdict(list)\n",
    "    q_list = [0] *(len(features_cols) + 1)\n",
    "    # calculate the real sample param\n",
    "    X = df[features_cols]\n",
    "    X['const'] = np.ones((num_sample))\n",
    "    X = X[['const', *features_cols]]\n",
    "    Y = df[labels_cols]\n",
    "    model = sm.OLS(Y, X)\n",
    "    model_res = model.fit()\n",
    "    b_r = model_res.params\n",
    "    for i in range(B):\n",
    "        new_df = df.sample(num_sample, replace=True)\n",
    "        X = new_df[features_cols]\n",
    "        X['const'] = np.ones((num_sample))\n",
    "        X = X[['const', *features_cols]]\n",
    "        Y = new_df[labels_cols]\n",
    "        model = sm.OLS(Y, X)\n",
    "        model_res = model.fit()\n",
    "        for i in range(len(features_cols) + 1):\n",
    "            g_dict[i].append((num_sample*0.5)*(model_res.params[i] - b_r[i]))\n",
    "    for i in range(len(features_cols) + 1):\n",
    "        q_list[i] = (np.quantile(g_dict[i], q), np.quantile(g_dict[i], alpha/2))\n",
    "    return q_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "047c226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qunatiles_list = cal_boot_pivot_quantile(400, pd.concat([df_train, y_train], axis=1),\n",
    "                        features_cols=['cigsPerDay', 'totChol', 'diaBP'], labels_cols=['sysBP'], alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "50b77f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivotal confidence intervals based on bootstrap for beta_0 is: [-127.43153470286313,141.09792080652448]\n",
      "Pivotal confidence intervals based on bootstrap for beta_1 is: [-1.2039774224066133,1.0182286653792771]\n",
      "Pivotal confidence intervals based on bootstrap for beta_2 is: [-0.24620662844857957,0.34909521215087314]\n",
      "Pivotal confidence intervals based on bootstrap for beta_3 is: [-0.14336329706831963,2.813442244844077]\n"
     ]
    }
   ],
   "source": [
    "for i, beta in enumerate(model_res.params):\n",
    "    print(f\"Pivotal confidence intervals based on bootstrap for beta_{i} is: [{beta - qunatiles_list[i][0]/np.sqrt(len(df_train))},{beta - qunatiles_list[i][1]/np.sqrt(len(df_train))}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3e0e7d",
   "metadata": {},
   "source": [
    "### Section 2 - confidence intervals based on quantiles method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d5f95a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_boot_quantile(B, df, features_cols, labels_cols, alpha):\n",
    "    num_sample = len(df)\n",
    "    q1 = 1 - (alpha / 2)\n",
    "    q2 = alpha / 2\n",
    "    g_dict = defaultdict(list)\n",
    "    q_list = [0] * (len(features_cols) + 1)\n",
    "    for i in range(B):\n",
    "        new_df = df.sample(num_sample, replace=True)\n",
    "        X = new_df[features_cols]\n",
    "        X['const'] = np.ones((num_sample))\n",
    "        X = X[['const', *features_cols]]\n",
    "        Y = new_df[labels_cols]\n",
    "        model = sm.OLS(Y, X)\n",
    "        model_res = model.fit()\n",
    "        for i in range(len(features_cols) + 1):\n",
    "            g_dict[i].append(model_res.params[i])\n",
    "    for i in range(len(features_cols) + 1):\n",
    "        q_list[i] = (np.quantile(g_dict[i], q2), np.quantile(g_dict[i], q1))\n",
    "    return q_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2d85b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_intervals = cal_boot_quantile(400, pd.concat([df_train, y_train], axis=1),\n",
    "                        features_cols=['cigsPerDay', 'totChol', 'diaBP'], labels_cols=['sysBP'], alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "433a57b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantiles confidence intervals based on bootstrap for beta_0 is: [-26.191722582780297,9.39111772814736]\n",
      "Quantiles confidence intervals based on bootstrap for beta_1 is: [-0.16510134713251584,0.16196614763752132]\n",
      "Quantiles confidence intervals based on bootstrap for beta_2 is: [0.014894140878829237,0.09629273737396721]\n",
      "Quantiles confidence intervals based on bootstrap for beta_3 is: [1.335482073336732,1.738878623676422]\n"
     ]
    }
   ],
   "source": [
    "for i, ci in enumerate(confidence_intervals):\n",
    "    print(f\"Quantiles confidence intervals based on bootstrap for beta_{i} is: [{ci[0]},{ci[1]}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c6405",
   "metadata": {},
   "source": [
    "**Calculating the parameters using the whole dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e249f5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const         5.611044\n",
       "cigsPerDay   -0.082200\n",
       "totChol       0.040282\n",
       "diaBP         1.422623\n",
       "dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.add_constant(df[['cigsPerDay', 'totChol', 'diaBP']])\n",
    "model = sm.OLS(df[['sysBP']],X)\n",
    "model_res = model.fit()\n",
    "model_res.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba131a45",
   "metadata": {},
   "source": [
    "### Comparing the confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13382cac",
   "metadata": {},
   "source": [
    "**Confidence intervals for $\\beta_0$**:<br>\n",
    "Confidence interval for beta_0 is: [-20.120873608415245,6.530840172599772]<br>\n",
    "Confidence interval based on bootstrap s.e for beta_0 is: [-23.24972522909058,9.659691793275108]<br>\n",
    "Pivotal confidence intervals based on bootstrap for beta_0 is: [-159.0955329137899,127.2672041798435]<br>\n",
    "Quantiles confidence intervals based on bootstrap for beta_0 is: [-28.044054623349616,9.120851869597175]<br>\n",
    "\n",
    "As we can see, the smallest interval was given by the normal approximation using the variance matrix.\n",
    "The next shortest interval was given by the qunatiles method, after that the confidence interval based on bootstrap s.e estimation and finally the pivotal condifence interval is the largest. <br>\n",
    "All of the confidence intervals contains the parameter $\\beta_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b234168",
   "metadata": {},
   "source": [
    "**Confidence intervals for $\\beta_1$**:<br>\n",
    "Confidence interval for beta_1 is: [-0.12499805793941654,0.12014199808401821] (0.24514) <br>\n",
    "Confidence interval based on bootstrap s.e for beta_1 is: [-0.12157323646605833,0.11671717661066] (0.23829)<br>\n",
    "Pivotal confidence intervals based on bootstrap for beta_1 is: [-1.0780884830760757,1.1102611332927885] (2.18835)<br>\n",
    "Quantiles confidence intervals based on bootstrap for beta_3 is: [-0.16041141204810144,0.1417458305429191] (0.30215) <br>\n",
    " \n",
    "This time the confidence interval given by the boostrap s.e estimation was the smallest, the next shortest interval was given by the normal approximation using the variance method. In a small gap behind them is the interval given by quantiles method and last but not least is the interval given by the pivot method. <br>\n",
    "All of the confidence intervals contains the parameter $\\beta_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f8e587",
   "metadata": {},
   "source": [
    "**Confidence intervals for $\\beta_2$**:<br>\n",
    "Confidence interval for beta_2 is: [0.024470264676292097,0.08700841545378751] (0.06253) <br>\n",
    "Confidence interval based on bootstrap s.e for beta_2 is: [0.021400344513457188,0.09007833561662243] (0.0686) <br>\n",
    "Pivotal confidence intervals based on bootstrap for beta_2 is: [-0.1950850780216041,0.36993707354491834] (0.565) <br>\n",
    "Quantiles confidence intervals based on bootstrap for beta_2 is: [0.01591730129880664,0.09482804535626096] (0.0789) <br>\n",
    " \n",
    "The shortest interval is given by the normal approximation method, the next shortest is the interval based on the bootstrap s.e estimation . Right after that is the interval based on the qunatile method and finally is the interval based on the pivot method. <br>\n",
    "All of the confidence intervals contains the parameter $\\beta_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a180745",
   "metadata": {},
   "source": [
    "**Confidence intervals for $\\beta_3$**:<br>\n",
    "Confidence interval for beta_3 is: [1.3755587622140237,1.6662906536246527] (0.29074) <br>\n",
    "Confidence interval based on bootstrap s.e for beta_3 is: [1.3426202113096413,1.6992292045290351] (0.35662) <br> \n",
    "Pivotal confidence intervals based on bootstrap for beta_3 is: [-0.017978470252370204,3.0708637474471248] (3.0887)<br>\n",
    "Quantiles confidence intervals based on bootstrap for beta_3 is: [1.3396107610635424,1.7668155629224438] (0.42719) <br>\n",
    "    \n",
    "The shortest interval is given by the normal approximation method, the next shortest is the interval based on the bootstrap s.e estimation . Right after that is the interval based on the qunatile method and finally is the interval based on the pivot method. <br>\n",
    "All of the confidence intervals contains the parameter $\\beta_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a5372",
   "metadata": {},
   "source": [
    "### Section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fd8c15",
   "metadata": {},
   "source": [
    "#### Section a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "77ef45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([df_test, y_test], axis=1).sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "50124556",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_100 = new_df[['sysBP']]\n",
    "new_df = new_df[['cigsPerDay', 'totChol', 'diaBP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "60f37ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "134ef367",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new_preds = model_res.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d27e11",
   "metadata": {},
   "source": [
    "#### Section b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4a74c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_bootstrap_normal_se_predict(B, df_train, X_test, features_cols, labels_cols):\n",
    "    df_test_len = len(X_test)\n",
    "    df_train_len = len(df_train)\n",
    "    predict_sum = np.zeros((df_test_len))\n",
    "    predict_sum2 = np.zeros((df_test_len))\n",
    "    for i in range(B):\n",
    "        boot_df = df_train.sample(replace=True, n=200)\n",
    "        y = boot_df[labels_cols]\n",
    "        X = boot_df[features_cols]\n",
    "        X['const'] = np.ones((df_train_len))\n",
    "        X = X[['const', *features_cols]]\n",
    "        model = sm.OLS(y,X)\n",
    "        model_res = model.fit()\n",
    "        predict_sum = predict_sum + model_res.predict(X_test)\n",
    "        predict_sum2 = predict_sum2 + (model_res.predict(X_test)) ** 2\n",
    "    return np.sqrt((1/B)*(predict_sum2) - ((1/B)*(predict_sum))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9fce14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_se = cal_bootstrap_normal_se_predict(400, pd.concat([df_train, y_train], axis=1),\n",
    "                        X, features_cols=['cigsPerDay', 'totChol', 'diaBP'], labels_cols=['sysBP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "79841b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new_cis = [(y_pred - ci_t_percentile*y_pred_se, y_pred + ci_t_percentile*y_pred_se)\n",
    "              for (y_pred, y_pred_se) in zip(y_new_preds, y_preds_se)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1fc82b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([y_new_ci[0] < y_new[0] < y_new_ci[1] for (y_new, y_new_ci) in zip(y_test_100.values, y_new_cis)])/100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc14831",
   "metadata": {},
   "source": [
    "### Trying to calculate confidence intervals in quantiles method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dcd00d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_bootstrap_quantile_predict(B, df_train, X_test, features_cols, labels_cols, alpha=0.05):\n",
    "    df_test_len = len(X_test)\n",
    "    df_train_len = len(df_train)\n",
    "    q1 = alpha / 2\n",
    "    q2 = 1 - q1\n",
    "    predict_dict = defaultdict(list)\n",
    "    q_list = [0] * (df_test_len)\n",
    "    for i in range(B):\n",
    "        boot_df = df_train.sample(replace=True, n=200)\n",
    "        y = boot_df[labels_cols]\n",
    "        X = boot_df[features_cols]\n",
    "        X['const'] = np.ones((df_train_len))\n",
    "        X = X[['const', *features_cols]]\n",
    "        model = sm.OLS(y,X)\n",
    "        model_res = model.fit()\n",
    "        pred = model_res.predict(X_test)\n",
    "        for j in range(df_test_len):\n",
    "            predict_dict[j].append(pred.iloc[j])\n",
    "    for i in range(df_test_len):\n",
    "        q_list[i] = (np.quantile(predict_dict[i], q1), np.quantile(predict_dict[i], q2))\n",
    "    return q_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dffe6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ci = cal_bootstrap_quantile_predict(400, pd.concat([df_train, y_train], axis=1),\n",
    "                        X, features_cols=['cigsPerDay', 'totChol', 'diaBP'], labels_cols=['sysBP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb5d91e",
   "metadata": {},
   "source": [
    "#### Section c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0ed828e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([y_new_ci[0] < y_new[0] < y_new_ci[1] for (y_new, y_new_ci) in zip(y_test_100.values, y_pred_ci)])/100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ca977d",
   "metadata": {},
   "source": [
    "#### Section d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafb3def",
   "metadata": {},
   "source": [
    "We seen in class that the confident interval for the $Y_{new}$ is $[\\hat{Y_{new}}\\pm z_{1-\\frac{\\alpha}{2}}\\hat{\\sigma_{\\epsilon}}\\sqrt{1+X_{new}^T(X^TX)^{-1}X_{new}}]$. The idea behind this modification in the confident interval is that we adding the estimator of the variance of the data to the variance of our model, which make the confident interval longer. So if we want to build a confident interval base of Bootstrap, we would make a small modification in our current Bootstrap confident interval : $[\\hat{Y^i}_{new}\\pm z_{\\frac{\\alpha}{2}}\\hat{S.E}_{bootstrap}], \\ when \\ \\hat{S.E}_{bootstrap}^2=\\underbrace{\\frac{1}{B}\\sum_{j=1}^{B}\\hat{(Y^j)^2}_{new}-\\frac{1}{B}(\\sum_{j=1}^{B}\\hat{(Y^j)}_{new})^2 }_{variance \\ of \\ the \\ model}+\\underbrace{\\frac{1}{B}\\sum_{j=1}^{B}\\hat{\\sigma^2_j}_{\\epsilon}}_{estimator \\ to \\ the \\ model \\ variance} $  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
